{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('features_30_sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc9_mean</th>\n",
       "      <th>mfcc9_var</th>\n",
       "      <th>mfcc10_mean</th>\n",
       "      <th>mfcc10_var</th>\n",
       "      <th>mfcc11_mean</th>\n",
       "      <th>mfcc11_var</th>\n",
       "      <th>mfcc12_mean</th>\n",
       "      <th>mfcc12_var</th>\n",
       "      <th>mfcc13_mean</th>\n",
       "      <th>mfcc13_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>3805.839606</td>\n",
       "      <td>9.015054e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.274110</td>\n",
       "      <td>82.204201</td>\n",
       "      <td>10.976572</td>\n",
       "      <td>63.386311</td>\n",
       "      <td>-8.326573</td>\n",
       "      <td>61.773094</td>\n",
       "      <td>8.803792</td>\n",
       "      <td>51.244125</td>\n",
       "      <td>-3.672300</td>\n",
       "      <td>41.217415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>3550.522098</td>\n",
       "      <td>2.977893e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.099661</td>\n",
       "      <td>166.108521</td>\n",
       "      <td>11.900497</td>\n",
       "      <td>104.358612</td>\n",
       "      <td>-5.555639</td>\n",
       "      <td>105.173630</td>\n",
       "      <td>5.376327</td>\n",
       "      <td>96.197212</td>\n",
       "      <td>-2.231760</td>\n",
       "      <td>64.914291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>3042.260232</td>\n",
       "      <td>7.840345e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.783643</td>\n",
       "      <td>65.447945</td>\n",
       "      <td>9.718760</td>\n",
       "      <td>67.908859</td>\n",
       "      <td>-13.133803</td>\n",
       "      <td>57.781425</td>\n",
       "      <td>5.791199</td>\n",
       "      <td>64.480209</td>\n",
       "      <td>-8.907628</td>\n",
       "      <td>60.385151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>2184.745799</td>\n",
       "      <td>1.493194e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759186</td>\n",
       "      <td>92.114090</td>\n",
       "      <td>8.137607</td>\n",
       "      <td>71.314079</td>\n",
       "      <td>-3.200653</td>\n",
       "      <td>110.236687</td>\n",
       "      <td>6.079319</td>\n",
       "      <td>48.251999</td>\n",
       "      <td>-2.480174</td>\n",
       "      <td>56.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>3579.757627</td>\n",
       "      <td>1.572978e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.793437</td>\n",
       "      <td>130.073349</td>\n",
       "      <td>1.207256</td>\n",
       "      <td>99.675575</td>\n",
       "      <td>-13.088418</td>\n",
       "      <td>80.254066</td>\n",
       "      <td>-2.813867</td>\n",
       "      <td>86.430626</td>\n",
       "      <td>-6.933385</td>\n",
       "      <td>89.555443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0          0.350088         0.088757  0.130228  0.002827   \n",
       "1          0.340914         0.094980  0.095948  0.002373   \n",
       "2          0.363637         0.085275  0.175570  0.002746   \n",
       "3          0.404785         0.093999  0.141093  0.006346   \n",
       "4          0.308526         0.087841  0.091529  0.002303   \n",
       "\n",
       "   spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0             1784.165850          129774.064525              2002.449060   \n",
       "1             1530.176679          375850.073649              2039.036516   \n",
       "2             1552.811865          156467.643368              1747.702312   \n",
       "3             1070.106615          184355.942417              1596.412872   \n",
       "4             1835.004266          343399.939274              1748.172116   \n",
       "\n",
       "   spectral_bandwidth_var  rolloff_mean   rolloff_var  ...  mfcc9_mean  \\\n",
       "0            85882.761315   3805.839606  9.015054e+05  ...  -12.274110   \n",
       "1           213843.755497   3550.522098  2.977893e+06  ...  -10.099661   \n",
       "2            76254.192257   3042.260232  7.840345e+05  ...  -11.783643   \n",
       "3           166441.494769   2184.745799  1.493194e+06  ...   -0.759186   \n",
       "4            88445.209036   3579.757627  1.572978e+06  ...  -11.793437   \n",
       "\n",
       "    mfcc9_var  mfcc10_mean  mfcc10_var  mfcc11_mean  mfcc11_var  mfcc12_mean  \\\n",
       "0   82.204201    10.976572   63.386311    -8.326573   61.773094     8.803792   \n",
       "1  166.108521    11.900497  104.358612    -5.555639  105.173630     5.376327   \n",
       "2   65.447945     9.718760   67.908859   -13.133803   57.781425     5.791199   \n",
       "3   92.114090     8.137607   71.314079    -3.200653  110.236687     6.079319   \n",
       "4  130.073349     1.207256   99.675575   -13.088418   80.254066    -2.813867   \n",
       "\n",
       "   mfcc12_var  mfcc13_mean  mfcc13_var  \n",
       "0   51.244125    -3.672300   41.217415  \n",
       "1   96.197212    -2.231760   64.914291  \n",
       "2   64.480209    -8.907628   60.385151  \n",
       "3   48.251999    -2.480174   56.799400  \n",
       "4   86.430626    -6.933385   89.555443  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data[data['label'].isin(['blues', 'classical', 'jazz', 'metal', 'pop'])].drop(['filename','length'],axis=1)\n",
    "dataset.iloc[:, :-15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler ,MinMaxScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = LabelEncoder().fit(dataset.iloc[:,-1])\n",
    "y= LabelEncoder().fit_transform(dataset.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 43)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler1 = MinMaxScaler().fit(np.array(dataset.iloc[:, :-15], dtype = float))\n",
    "scaler2 = StandardScaler().fit(np.array(dataset.iloc[:, :-15], dtype = float))\n",
    "X = StandardScaler().fit_transform(np.array(dataset.iloc[:, :-15], dtype = float))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (350, 43) (350,)\n",
      "Test set: (150, 43) (150,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=42)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our regression model \n",
    "n_cols = dataset.iloc[:, :-15].shape[1]\n",
    "def regression_model_1():\n",
    "    # structure of our model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu',))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            )\n",
    "Callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 350 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "350/350 [==============================] - 1s 4ms/step - loss: 2.0630 - accuracy: 0.2143 - val_loss: 1.5512 - val_accuracy: 0.4067\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 1.4828 - accuracy: 0.4457 - val_loss: 1.4632 - val_accuracy: 0.5133\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 1.1352 - accuracy: 0.5829 - val_loss: 1.3778 - val_accuracy: 0.5733\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 0s 88us/step - loss: 1.0223 - accuracy: 0.6000 - val_loss: 1.3066 - val_accuracy: 0.6467\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.8530 - accuracy: 0.6914 - val_loss: 1.2449 - val_accuracy: 0.6600\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.7757 - accuracy: 0.7343 - val_loss: 1.1917 - val_accuracy: 0.7133\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.7184 - accuracy: 0.7600 - val_loss: 1.1436 - val_accuracy: 0.7400\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.6350 - accuracy: 0.7943 - val_loss: 1.1005 - val_accuracy: 0.7600\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.6211 - accuracy: 0.7829 - val_loss: 1.0601 - val_accuracy: 0.7867\n",
      "Epoch 10/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.5631 - accuracy: 0.8000 - val_loss: 1.0227 - val_accuracy: 0.7800\n",
      "Epoch 11/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.5404 - accuracy: 0.8200 - val_loss: 0.9885 - val_accuracy: 0.7867\n",
      "Epoch 12/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.4609 - accuracy: 0.8571 - val_loss: 0.9570 - val_accuracy: 0.7867\n",
      "Epoch 13/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.4287 - accuracy: 0.8743 - val_loss: 0.9252 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "350/350 [==============================] - 0s 103us/step - loss: 0.4282 - accuracy: 0.8657 - val_loss: 0.8964 - val_accuracy: 0.8067\n",
      "Epoch 15/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3613 - accuracy: 0.8943 - val_loss: 0.8697 - val_accuracy: 0.8133\n",
      "Epoch 16/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3892 - accuracy: 0.8886 - val_loss: 0.8434 - val_accuracy: 0.8133\n",
      "Epoch 17/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3527 - accuracy: 0.8800 - val_loss: 0.8171 - val_accuracy: 0.8267\n",
      "Epoch 18/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.3385 - accuracy: 0.9086 - val_loss: 0.7902 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3053 - accuracy: 0.9143 - val_loss: 0.7670 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "350/350 [==============================] - 0s 108us/step - loss: 0.2928 - accuracy: 0.9143 - val_loss: 0.7451 - val_accuracy: 0.8400\n",
      "Epoch 21/100\n",
      "350/350 [==============================] - 0s 103us/step - loss: 0.2888 - accuracy: 0.9200 - val_loss: 0.7217 - val_accuracy: 0.8400\n",
      "Epoch 22/100\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.2947 - accuracy: 0.9057 - val_loss: 0.7008 - val_accuracy: 0.8400\n",
      "Epoch 23/100\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.2740 - accuracy: 0.9257 - val_loss: 0.6795 - val_accuracy: 0.8400\n",
      "Epoch 24/100\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.2711 - accuracy: 0.9029 - val_loss: 0.6588 - val_accuracy: 0.8400\n",
      "Epoch 25/100\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.2654 - accuracy: 0.9257 - val_loss: 0.6407 - val_accuracy: 0.8467\n",
      "Epoch 26/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.2448 - accuracy: 0.9286 - val_loss: 0.6200 - val_accuracy: 0.8533\n",
      "Epoch 27/100\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.2159 - accuracy: 0.9429 - val_loss: 0.5993 - val_accuracy: 0.8467\n",
      "Epoch 28/100\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.2314 - accuracy: 0.9343 - val_loss: 0.5798 - val_accuracy: 0.8533\n",
      "Epoch 29/100\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.2088 - accuracy: 0.9400 - val_loss: 0.5601 - val_accuracy: 0.8600\n",
      "Epoch 30/100\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.1829 - accuracy: 0.9629 - val_loss: 0.5412 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.1772 - accuracy: 0.9543 - val_loss: 0.5228 - val_accuracy: 0.8800\n",
      "Epoch 32/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.1878 - accuracy: 0.9514 - val_loss: 0.5060 - val_accuracy: 0.8867\n",
      "Epoch 33/100\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.1869 - accuracy: 0.9486 - val_loss: 0.4894 - val_accuracy: 0.8933\n",
      "Epoch 34/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.1669 - accuracy: 0.9600 - val_loss: 0.4745 - val_accuracy: 0.8933\n",
      "Epoch 35/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1510 - accuracy: 0.9714 - val_loss: 0.4629 - val_accuracy: 0.8867\n",
      "Epoch 36/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1919 - accuracy: 0.9486 - val_loss: 0.4529 - val_accuracy: 0.8867\n",
      "Epoch 37/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1500 - accuracy: 0.9657 - val_loss: 0.4442 - val_accuracy: 0.8867\n",
      "Epoch 38/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1499 - accuracy: 0.9629 - val_loss: 0.4343 - val_accuracy: 0.8800\n",
      "Epoch 39/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1365 - accuracy: 0.9657 - val_loss: 0.4257 - val_accuracy: 0.8800\n",
      "Epoch 40/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1491 - accuracy: 0.9686 - val_loss: 0.4170 - val_accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1329 - accuracy: 0.9629 - val_loss: 0.4086 - val_accuracy: 0.8933\n",
      "Epoch 42/100\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.1228 - accuracy: 0.9686 - val_loss: 0.4016 - val_accuracy: 0.8867\n",
      "Epoch 43/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1254 - accuracy: 0.9714 - val_loss: 0.3951 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 44/100\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.1174 - accuracy: 0.9800 - val_loss: 0.3911 - val_accuracy: 0.8800\n",
      "Epoch 45/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1224 - accuracy: 0.9771 - val_loss: 0.3879 - val_accuracy: 0.8867\n",
      "Epoch 46/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.1156 - accuracy: 0.9657 - val_loss: 0.3841 - val_accuracy: 0.8867\n",
      "Epoch 47/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1024 - accuracy: 0.9771 - val_loss: 0.3802 - val_accuracy: 0.8867\n",
      "Epoch 48/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1096 - accuracy: 0.9800 - val_loss: 0.3760 - val_accuracy: 0.8867\n",
      "Epoch 49/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1202 - accuracy: 0.9714 - val_loss: 0.3720 - val_accuracy: 0.8867\n",
      "Epoch 50/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1323 - accuracy: 0.9714 - val_loss: 0.3684 - val_accuracy: 0.8800\n",
      "Epoch 51/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1218 - accuracy: 0.9743 - val_loss: 0.3655 - val_accuracy: 0.8800\n",
      "Epoch 52/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1151 - accuracy: 0.9743 - val_loss: 0.3617 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.1260 - accuracy: 0.9686 - val_loss: 0.3589 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 54/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1150 - accuracy: 0.9771 - val_loss: 0.3568 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "350/350 [==============================] - 0s 80us/step - loss: 0.1163 - accuracy: 0.9886 - val_loss: 0.3546 - val_accuracy: 0.8800\n",
      "Epoch 56/100\n",
      "350/350 [==============================] - 0s 77us/step - loss: 0.1148 - accuracy: 0.9771 - val_loss: 0.3527 - val_accuracy: 0.8800\n",
      "Epoch 57/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1100 - accuracy: 0.9771 - val_loss: 0.3498 - val_accuracy: 0.8800\n",
      "Epoch 58/100\n",
      "350/350 [==============================] - 0s 80us/step - loss: 0.1262 - accuracy: 0.9714 - val_loss: 0.3486 - val_accuracy: 0.8800\n",
      "Epoch 59/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1158 - accuracy: 0.9771 - val_loss: 0.3461 - val_accuracy: 0.8800\n",
      "Epoch 60/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1259 - accuracy: 0.9743 - val_loss: 0.3443 - val_accuracy: 0.8800\n",
      "Epoch 61/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1271 - accuracy: 0.9686 - val_loss: 0.3428 - val_accuracy: 0.8800\n",
      "Epoch 62/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1096 - accuracy: 0.9743 - val_loss: 0.3408 - val_accuracy: 0.8800\n",
      "Epoch 63/100\n",
      "350/350 [==============================] - 0s 77us/step - loss: 0.1299 - accuracy: 0.9657 - val_loss: 0.3389 - val_accuracy: 0.8733\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 64/100\n",
      "350/350 [==============================] - 0s 80us/step - loss: 0.1147 - accuracy: 0.9771 - val_loss: 0.3372 - val_accuracy: 0.8733\n",
      "Epoch 65/100\n",
      "350/350 [==============================] - 0s 86us/step - loss: 0.1034 - accuracy: 0.9771 - val_loss: 0.3354 - val_accuracy: 0.8733\n",
      "Epoch 66/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1054 - accuracy: 0.9800 - val_loss: 0.3335 - val_accuracy: 0.8733\n",
      "Epoch 67/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1298 - accuracy: 0.9629 - val_loss: 0.3317 - val_accuracy: 0.8733\n",
      "Epoch 68/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1172 - accuracy: 0.9829 - val_loss: 0.3302 - val_accuracy: 0.8733\n",
      "Epoch 69/100\n",
      "350/350 [==============================] - 0s 80us/step - loss: 0.1056 - accuracy: 0.9829 - val_loss: 0.3287 - val_accuracy: 0.8733\n",
      "Epoch 70/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.0948 - accuracy: 0.9943 - val_loss: 0.3273 - val_accuracy: 0.8733\n",
      "Epoch 71/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1095 - accuracy: 0.9857 - val_loss: 0.3264 - val_accuracy: 0.8733\n",
      "Epoch 72/100\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.1067 - accuracy: 0.9771 - val_loss: 0.3251 - val_accuracy: 0.8733\n",
      "Epoch 73/100\n",
      "350/350 [==============================] - 0s 114us/step - loss: 0.1235 - accuracy: 0.9829 - val_loss: 0.3234 - val_accuracy: 0.8733\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 74/100\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.1411 - accuracy: 0.9571 - val_loss: 0.3219 - val_accuracy: 0.8733\n",
      "Epoch 75/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.1132 - accuracy: 0.9800 - val_loss: 0.3207 - val_accuracy: 0.8733\n",
      "Epoch 76/100\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.1345 - accuracy: 0.9629 - val_loss: 0.3195 - val_accuracy: 0.8733\n",
      "Epoch 77/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1335 - accuracy: 0.9657 - val_loss: 0.3182 - val_accuracy: 0.8733\n",
      "Epoch 78/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1292 - accuracy: 0.9800 - val_loss: 0.3177 - val_accuracy: 0.8733\n",
      "Epoch 79/100\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.1226 - accuracy: 0.9686 - val_loss: 0.3165 - val_accuracy: 0.8733\n",
      "Epoch 80/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1163 - accuracy: 0.9714 - val_loss: 0.3158 - val_accuracy: 0.8733\n",
      "Epoch 81/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1282 - accuracy: 0.9714 - val_loss: 0.3152 - val_accuracy: 0.8733\n",
      "Epoch 82/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.1268 - accuracy: 0.9714 - val_loss: 0.3144 - val_accuracy: 0.8800\n",
      "Epoch 83/100\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.1265 - accuracy: 0.9686 - val_loss: 0.3140 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 84/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1538 - accuracy: 0.9600 - val_loss: 0.3133 - val_accuracy: 0.8800\n",
      "Epoch 85/100\n",
      "350/350 [==============================] - 0s 83us/step - loss: 0.1187 - accuracy: 0.9800 - val_loss: 0.3125 - val_accuracy: 0.8800\n",
      "Epoch 86/100\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.1151 - accuracy: 0.9714 - val_loss: 0.3114 - val_accuracy: 0.8800\n",
      "Epoch 87/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1123 - accuracy: 0.9771 - val_loss: 0.3102 - val_accuracy: 0.8800\n",
      "Epoch 88/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1156 - accuracy: 0.9771 - val_loss: 0.3092 - val_accuracy: 0.8800\n",
      "Epoch 89/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1216 - accuracy: 0.9714 - val_loss: 0.3087 - val_accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.1154 - accuracy: 0.9829 - val_loss: 0.3078 - val_accuracy: 0.8800\n",
      "Epoch 91/100\n",
      "350/350 [==============================] - 0s 85us/step - loss: 0.1103 - accuracy: 0.9714 - val_loss: 0.3071 - val_accuracy: 0.8800\n",
      "Epoch 92/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1289 - accuracy: 0.9743 - val_loss: 0.3064 - val_accuracy: 0.8800\n",
      "Epoch 93/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1278 - accuracy: 0.9771 - val_loss: 0.3059 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 94/100\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.1140 - accuracy: 0.9829 - val_loss: 0.3053 - val_accuracy: 0.8800\n",
      "Epoch 95/100\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.1230 - accuracy: 0.9800 - val_loss: 0.3046 - val_accuracy: 0.8800\n",
      "Epoch 96/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1094 - accuracy: 0.9829 - val_loss: 0.3040 - val_accuracy: 0.8800\n",
      "Epoch 97/100\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.1196 - accuracy: 0.9743 - val_loss: 0.3035 - val_accuracy: 0.8800\n",
      "Epoch 98/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1312 - accuracy: 0.9629 - val_loss: 0.3028 - val_accuracy: 0.8800\n",
      "Epoch 99/100\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.1293 - accuracy: 0.9800 - val_loss: 0.3022 - val_accuracy: 0.8800\n",
      "Epoch 100/100\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.1270 - accuracy: 0.9714 - val_loss: 0.3014 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x274464ef400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the model\n",
    "# model_1 = regression_model_1()\n",
    "\n",
    "#fit the model\n",
    "# model_1.fit(X_train,y_train, callbacks=Callbacks , validation_data=(X_test,y_test) ,epochs=100,batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.save('Keras_reg_30sec_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Keras_reg_30sec_5.h5')\n",
    "predictions = model.predict_classes(X_test)\n",
    "score = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 3 1 1 3 3 1 0 4 0 1 4 0 3 3 4 0 3 4 4 4 2 3 0 4 4 2 1 3 4 3 4 1 0 3 4\n",
      " 0 2 0 3 0 4 1 0 0 0 0 4 0 0 1 1 4 1 0 1 0 2 0 4 2 3 4 0 0 4 0 2 3 3 3 2 2\n",
      " 3 3 2 0 4 4 1 0 4 1 3 0 1 4 3 2 3 4 3 3 4 3 0 0 4 0 2 4 0 3 3 0 3 2 3 1 1\n",
      " 4 3 0 4 2 2 2 1 0 2 1 3 1 2 2 4 2 1 3 0 1 4 2 1 0 1 0 0 2 0 2 4 0 2 2 0 2\n",
      " 2 4]\n",
      "[3 0 3 1 1 3 3 1 0 4 0 1 2 0 3 0 4 0 3 4 4 4 2 3 0 4 4 2 1 3 4 3 4 1 0 3 4\n",
      " 0 1 0 3 2 4 1 0 0 0 0 4 0 0 1 1 4 1 0 2 2 2 0 4 2 3 4 3 0 4 0 2 0 3 3 2 2\n",
      " 3 3 2 0 4 4 2 0 4 1 3 0 2 3 3 2 3 4 3 3 4 3 0 0 4 0 0 4 0 0 3 0 3 2 3 1 1\n",
      " 4 3 0 4 2 2 2 1 0 2 1 3 1 2 2 4 1 1 3 0 1 4 2 1 0 1 0 0 2 0 0 2 0 2 1 2 2\n",
      " 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0  3  1  0]\n",
      " [ 0 20  3  0  0]\n",
      " [ 2  3 21  0  0]\n",
      " [ 3  0  0 28  0]\n",
      " [ 0  0  2  1 28]]\n"
     ]
    }
   ],
   "source": [
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25fffa837f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "classes=['blues', 'classical', 'jazz', 'metal', 'pop']\n",
    "sns.heatmap(cf_matrix, annot=True , cmap='Blues',xticklabels=classes,yticklabels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test_30_sec.csv')\n",
    "dataset_test= data_test.drop(['filename','length'],axis=1)\n",
    "X__test=scaler2.transform(np.array(dataset_test.iloc[:, :-15], dtype = float))\n",
    "actual = encode.transform(dataset_test.iloc[:,-1])\n",
    "pred = model.predict_classes(X__test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 4 1 1 0 3 4 4 1 4 4 4 0 4 0 0 2 2 1 3 0 2 3 2 2 4 4 1]\n",
      "[3 3 4 1 1 0 3 4 4 1 4 2 4 4 4 0 0 2 2 1 3 2 2 4 2 2 2 4 2]\n"
     ]
    }
   ],
   "source": [
    "# blues[0],classical[1],jazz[2],metal[3],pop[4]\n",
    "print(actual)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25f85773668>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix_test = confusion_matrix(actual,pred)\n",
    "classes=['blues', 'classical','jazz', 'metal', 'pop']\n",
    "sns.heatmap(cf_matrix_test, annot=True , cmap='Blues',xticklabels=classes,yticklabels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
